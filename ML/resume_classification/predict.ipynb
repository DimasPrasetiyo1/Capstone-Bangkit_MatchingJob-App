{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import urllib\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model and tokenizer\n",
    "model = tf.keras.models.load_model('resume_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {'HR': 0, 'DESIGNER': 1, 'INFORMATION-TECHNOLOGY': 2, 'TEACHER': 3, 'ADVOCATE': 4, 'BUSINESS-DEVELOPMENT': 5, 'HEALTHCARE': 6, 'FITNESS': 7, 'AGRICULTURE': 8, 'BPO': 9, 'SALES': 10, 'CONSULTANT': 11, 'DIGITAL-MEDIA': 12, 'AUTOMOBILE': 13, 'CHEF': 14, 'FINANCE': 15, 'APPAREL': 16, 'ENGINEERING': 17, 'ACCOUNTANT': 18, 'CONSTRUCTION': 19, 'PUBLIC-RELATIONS': 20, 'BANKING': 21, 'ARTS': 22, 'AVIATION': 23, 'Data Science': 24, 'Advocate': 25, 'Arts': 26, 'Web Designing': 27, 'Mechanical Engineer': 28, 'Sales': 29, 'Health and fitness': 30, 'Civil Engineer': 31, 'Java Developer': 32, 'Business Analyst': 33, 'SAP Developer': 34, 'Automation Testing': 35, 'Electrical Engineering': 36, 'Operations Manager': 37, 'Python Developer': 38, 'DevOps Engineer': 39, 'Network Security Engineer': 40, 'PMO': 41, 'Database': 42, 'Hadoop': 43, 'ETL Developer': 44, 'DotNet Developer': 45, 'Blockchain': 46, 'Testing': 47}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "HR\n"
     ]
    }
   ],
   "source": [
    "new_text = ['this is a sample resume']\n",
    "#convert to sequences\n",
    "new_text_sequences = tokenizer.texts_to_sequences(new_text)\n",
    "#pad the sequences\n",
    "new_text_padded = pad_sequences(new_text_sequences, padding='post', maxlen=768)\n",
    "#make predictions\n",
    "pred = model.predict(tf.expand_dims(new_text_padded[0], axis=0))\n",
    "#argmax to get max value\n",
    "pred = np.argmax(pred)\n",
    "\n",
    "for key, value in class_mapping.items():\n",
    "    if pred == value:\n",
    "        print(key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-exam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
